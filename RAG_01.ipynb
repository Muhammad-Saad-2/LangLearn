{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOSWmZh2gkqad5BzQPABMBi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Saad-2/LangLearn/blob/main/RAG_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#installing encessary libraries\n",
        "\n",
        "%pip install langchain -q -U\n",
        "%pip install langchain-community -q -U\n",
        "%pip install langchain-huggingface -q -U\n",
        "%pip install langchain_pinecone -q -U\n",
        "%pip install sentence-transformers -q -U\n",
        "%pip install langchain-google-genai -q -U\n",
        "%pip install langchain-pinecone -q -U"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zYOW0SgaluWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7221322-f986-4f5f-8a41-c81852faec38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "import time\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pinecone_api_key = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "pc =  Pinecone(api_key=pinecone_api_key) #create instance from the pinecone class"
      ],
      "metadata": {
        "id": "1VeSYNEGly9R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "index_name = \"ragexplore\"\n",
        "\n",
        "existing_indexes = pc.list_indexes()\n",
        "if index_name not in [index.name for index in existing_indexes]:\n",
        "  pc.create_index(\n",
        "      name=index_name,\n",
        "      dimension=768,\n",
        "      metric=\"cosine\",\n",
        "      spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "  )\n",
        "else:\n",
        "  print(\"index already exists\")\n",
        "\n",
        "index = pc.Index(index_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHBJ5XH32Ij0",
        "outputId": "97d465ec-ee53-4a6d-9547-1bc1d509794f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index already exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc.describe_index(index_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fowHbJMP2_UI",
        "outputId": "7516ccd2-1639-4893-c6f0-f9b27040b561"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'deletion_protection': 'disabled',\n",
            " 'dimension': 768,\n",
            " 'host': 'ragexplore-q2q9tvj.svc.aped-4627-b74a.pinecone.io',\n",
            " 'metric': 'cosine',\n",
            " 'name': 'ragexplore',\n",
            " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
            " 'status': {'ready': True, 'state': 'Ready'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text embedding instance\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "embedding = SentenceTransformer( \"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "vector_store = PineconeVectorStore(\n",
        "    index=index,\n",
        "    embedding=embedding,\n",
        "    text_key=\"text\"\n",
        "\n",
        "  )\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZsaH6u2FJAAV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dummy docuemnts\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from uuid import uuid4\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
        "    metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
        ")\n",
        "document_2 = Document(\n",
        "    page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
        "    metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
        ")\n",
        "document_3 = Document(\n",
        "    page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
        "    metadata={\"year\": 200, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
        ")\n",
        "document_4 = Document(\n",
        "    page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
        "    metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
        ")\n",
        "document_5 = Document(\n",
        "    page_content=\"Toys come alive and have a blast doing so\",\n",
        "    metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
        ")\n",
        "document_6 = Document(\n",
        "    page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
        "    metadata={\"year\": 19, \"rating\": 8.3},\n",
        ")\n",
        "document_7 = Document(\n",
        "    page_content=\"In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization\",\n",
        "    metadata={\"year\": 2004, \"director\": \"Steven Spielberg\", \"rating\": 8.6},\n",
        ")\n",
        "document_8 = Document(\n",
        "    page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
        "    metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
        ")\n",
        "document_9 = Document(\n",
        "    page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
        "    metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
        ")\n",
        "document_10 = Document(\n",
        "    page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
        "    metadata={\"year\": 200, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10\n",
        "  ]\n",
        "\n",
        "#assigning uuids to each document\n",
        "uuids = [str(uuid4()) for doc in range (0, len(documents))]\n",
        "\n"
      ],
      "metadata": {
        "id": "4b925s8qRfhB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#passing the generated data into the embedding model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "embeddings = []\n",
        "\n",
        "for i, document in enumerate(documents):\n",
        "  embedding = model.encode(document.page_content)\n",
        "  embeddings.append(embedding)\n",
        "\n",
        "  #storing the index value to the index\n",
        "  index.upsert(\n",
        "      vectors=[(uuids[i], embedding.tolist(), document.metadata)],\n",
        "      namespace=\"namespcae_1\"\n",
        "  )"
      ],
      "metadata": {
        "id": "poL_fIv6tQ9Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdjqBeps3NDy",
        "outputId": "117f2a1c-0dcc-4777-b6f0-c459d94bcfd3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.03193135  0.09707245 -0.02372342  0.00645191 -0.07106198 -0.01199914\n",
            "  0.00028392  0.0083367  -0.03558818  0.00582182  0.06212223 -0.01217275\n",
            " -0.01298265  0.0604606  -0.01561258 -0.03253571 -0.03677248  0.02432382\n",
            " -0.03235717 -0.01409195]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "\n",
        "# Replace with your actual API key\n",
        "google_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Initialize the Gemini model, using 'gemini-pro' as the model family\n",
        "# Valid options for model include: 'gemini-pro', 'gemini-turbo', 'text-bison@001'\n",
        "llm = GoogleGenerativeAI(model=\"gemini-pro\", api_key=google_api_key, temperature=0.7)  # Adjust temperature as needed\n",
        "\n",
        "# Example usage with the documents and embeddings\n",
        "generated_text = llm.invoke(\n",
        "    \"Generate a creative text that incorporates information from these movie summaries:\\n\\n\"\n",
        "    + \"\\n\\n\".join([doc.page_content for doc in documents])\n",
        "    + \"\\n\\nThe new text should be a cohesive story, not just a summary.\"\n",
        ")\n",
        "generated_text"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "rTAVOLKTGGum",
        "outputId": "04f0be64-16cc-4c7c-a302-7c56464c2734"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"In a realm where reality and dreams intertwined, a team of audacious scientists dared to resurrect the colossal creatures of the past. Chaos erupted as dinosaurs rampaged through the modern world.\\n\\nMeanwhile, amidst the labyrinthine corridors of the human mind, Leo DiCaprio found himself trapped in an endless spiral of dreams. Each layer peeled back, revealing a deeper and more enigmatic world, the boundaries between reality and fantasy blurring.\\n\\nA brilliant psychologist, lured into the depths of the subconscious, navigated a treacherous maze of dreams within dreams within dreams. The line between inception and the reality of his own mind became dangerously thin.\\n\\nIn a quaint town, wholesome women radiated an aura of tranquility, their simple lives a stark contrast to the turmoil unfolding elsewhere. Yet, their charm proved irresistible to a group of men who yearned for their company.\\n\\nAs the sun dipped below the horizon, toys sprang to life, their laughter echoing through the empty streets. They reveled in their newfound freedom, their plastic bodies filled with boundless joy and mischief.\\n\\nBeyond Earth's embrace, in the desolate Zone, three men embarked on a perilous journey. Their minds and bodies pushed to the brink, they returned transformed, forever haunted by the secrets they had witnessed.\\n\\nOn the distant moon of Pandora, a paraplegic Marine found himself torn between loyalty to his mission and the allure of an alien civilization. Amidst the vibrant bioluminescent forests, he discovered a profound connection with the indigenous inhabitants, their wisdom echoing through the stars.\\n\\nAnd so, in this tapestry of dreams, reality, and the yearning for connection, the boundaries between the tangible and the intangible blurred, leaving behind a haunting legacy of wonder, chaos, and the eternal search for meaning.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fetch the value of document_1 using index.fetch method\n",
        "fetched_doc = index.fetch(ids=[uuids[0]], namespace=\"namespcae_1\")\n",
        "fetched_doc\n"
      ],
      "metadata": {
        "id": "nNmakQuDay-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NEQU-eF4cx4P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}